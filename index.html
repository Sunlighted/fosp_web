<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Safe Model-based Reinforcement Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FOSP: Fine-tuning Offline Safe Policy through World Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FOSP: Fine-tuning Offline Safe Policy through World Models</h1>
          <div class="is-size-5 publication-authors">
<!--             <span class="author-block">
              <a href="">Anonymous Authors</a><sup></sup></span> -->
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=uSpiLrMAAAAJ">Chenyang Cao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Yucheng Xin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Silang Wu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://say-hello2y.github.io/">Longxiang He</a><sup>1</sup>,
            </span>
            <span class="author-achor">
              <a href="https://scholar.google.com.hk/citations?user=hhl2kHoAAAAJ&hl=zh-CN">Zichen Yan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=kV-h3B8AAAAJ&hl=en&oi=ao">Junbo Tan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=h9dN_ykAAAAJ&hl=en&oi=ao">Xueqian Wang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>SIGS, Tsinghua University,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-achor"><sup>2</sup>College of Design and Engineering, National University of Singapore.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=dbuFJg7eaw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2407.04942"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=OQOYVLgvEoM&list=PLcOosLaucWFNilsP4tp5G__Mcv0CDHTc2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(Coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data(Coming soon)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Model-based Reinforcement Learning (RL) has shown its high training efficiency and capability of handling high-dimensional tasks. 
            Regarding safety issues, safe model-based RL can achieve nearly zero-cost performance and effectively manage the trade-off between performance and safety. 
            Nevertheless, prior works still pose safety challenges due to the online exploration in real-world deployment. 
            To address this, some offline RL methods have emerged as solutions, which learn from a static dataset in a safe way by avoiding interactions with the environment. 
          </p>
          <p>
            In this paper, we aim to further enhance safety during the deployment stage for vision-based robotic tasks by fine-tuning an offline-trained policy. 
            We incorporate in-sample optimization, model-based policy expansion, and reachability guidance to construct a safe offline-to-online framework. 
            Moreover, our method proves to improve the generalization of offline policy in unseen safety-constrained scenarios. 
            Finally, the efficiency of our method is validated on simulation benchmarks with five vision-only tasks and a real robot by solving some deployment problems using limited data.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper Pic. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <!-- <p>
          The framework of Model-based Fine-tuning Offline Safe Policy
        </p> -->
        <div class="publication-video">
          <img src="./static/images/main.jpg"
                 class="interpolation-image"
                 alt="FOSP: The framework of Model-based Fine-tuning Offline Safe Policy"/></img>
        </div>
      </div>
    </div>
    <!--/ Paper Pic. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video id="final-video" controls playsinline height="100%">
              <source src="./static/videos/video.mp4"
                      type="video/mp4">
          <\video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <!-- Unified Title -->
      <div class="column is-full">
        <h2 class="title is-3">Real world experiments comparing with the baseline</h2>
        <p>
          We compare FOSP with a strong baseline: SafeDreamer, which is currently the SOTA model for visual safety reinforcement learning.
          We show a different example of the tasks. The standard task can be finished after offline training by FOSP and SafeDreamer. 
          After training, the FOSP is deployed in the real world directly and fine-tuned for 40 steps.
          Keeping all other conditions the same, we also fine-tune SafeDreamer 40 steps in these transfer tasks.
          While SafeDreamer is struggling to finish the tasks, FOSP can easily avoid the obstacles and find the goals.
        </p>
      </div>
    </div>

    <!-- 1 -->
    <div class="columns is-centered">

      <div class="column">
      </div>

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Standard task</h3>
          <p>
            Using the offline trained model to plan a safe route to the goal with enough data. 
            It shows the capability to finish the standard task.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/2suc.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <div class="column">
      </div>
    </div>
  </div>

    <!-- 2 -->

    <div class="container is-max-desktop">
  
      <div class="columns is-centered">
        <!-- suc1 -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 1</h3>
            <p>
              Change the shape of obstacles while using FOSP. 
            </p>
            <video id="new-module-video" controls playsinline height="100%">
              <source src="./static/videos/2suc1.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <!-- suc2. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 2</h3>
            <p>
              Change the shape of goal while using FOSP. 
            </p>
            <video id="new-module-video" controls playsinline height="100%">
              <source src="./static/videos/2suc2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        
        <!-- suc3 -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 3</h3>
            <p>
              Change the number of obstacles while using FOSP. 
            </p>
            <video id="new-module-video" controls playsinline height="100%">
              <source src="./static/videos/2suc3.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

      <!-- 3 -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <!-- fail1 -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 1(baseline)</h3>
            <p>
              Change the shape of obstacles while using the baseline. 
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/2fail1.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
  
        <!-- fail2. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 2(baseline)</h3>
            <p>
              Change the shape of the goal while using the baseline. 
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/2fail2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        
        <!-- fail3 -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Transfer 3(baseline)</h3>
            <p>
              Change the number of obstacles while using the baseline. 
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/2fail3.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Simple example</h3>
        <div class="content has-text-justified">
          <p>
            We collect the dataset in the following way: using 3Dconnexion to teleoperate the robot arm and the camera to perception throughout the experiment process.
            We collect trajectories and then mix them together for training. A trajectory that the robot almost reaches the target but doesn't reach it accurately is shown:
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                class="interpolation-image"
                alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-1">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info is-centered"
                  id="interpolation-slider"
                  step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                class="interpolation-image"
                alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <div class="content has-text-justified">
          <p>
            A trajectory that the robot successfully reaches the goal without collision is shown:
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start-1.jpg"
                class="interpolation-image"
                alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-2">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info is-centered"
                  id="interpolation-slider-2"
                  step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end-1.jpg"
                class="interpolation-image"
                alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->
        <div class="content has-text-justified">
          <p>
            The following picture shows four different trajectories: whether the target was reached and whether constraints were violated. Among them, the red-framed part shows 
            when the robotic arm collides with obstacles and the yellow-framed part indicates the robotic arm reaches the goal.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <!-- <div class="column is-3 has-text-centered"> -->
          <img src="./static/images/data.jpg"
                class="interpolation-image"
                alt="Experienment data"/>
        </div>
    

      </div>
    </div>
  </div>
</section>

    <!-- Animation. -->
    <section class="section">
      <div class="container is-max-desktop">

        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Experienments</h2>

            <!-- Interpolating. -->
            <h3 class="title is-4">Environment and tasks</h3>
            <div class="content has-text-justified">
              <p>
                Different tasks and agents in the simulation and the real world. Simulation tasks: we consider four different tasks in the simulation: Push1,
                Goal1, Button1, Goal2. Agent type: Car (upper) and Point (lower). Real-robot setup: we use raw images as inputs and enable the robotic arm to complete
                obstacle avoidance tasks safely.
              </p>
            </div>
            <div class="columns is-vcentered interpolation-panel">
              <img src="./static/images/env.png"
                    class="interpolation-image"
                    alt="Experienment env"/>
            </div>
            <br/>

            <div class="content has-text-justified">
              <p>
                These are some visual representations of our algorithm in real-world tasks. 
                The agent's observations before and after are saved as animations. 
                The agent also makes decisions based on first-person image-only information.
              </p>
            </div>
            <div class="columns is-centered">
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointGoal1(front)</h3>
                  <img src="./static/images/goal1-1.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointGoal1(back)</h3>
                  <img src="./static/images/goal1-2.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
            </div>
            
            <div class="columns is-centered">
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointGoal2(front)</h3>
                  <img src="./static/images/goal2-1.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointGoal2(back)</h3>
                  <img src="./static/images/goal2-2.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
            </div>

            <div class="columns is-centered">
              <!-- suc1 -->
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointButton1(front)</h3>
                  <img src="./static/images/button1.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointButton1(back)</h3>
                  <img src="./static/images/button2.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
            </div>

            <div class="columns is-centered">
              <!-- suc1 -->
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointPush1(front)</h3>
                  <img src="./static/images/push1.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafePointPush1(back)</h3>
                  <img src="./static/images/push2.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
            </div>

            <div class="columns is-centered">
              <!-- suc1 -->
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafeCarGoal2(front)</h3>
                  <img src="./static/images/carg1.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
              <div class="column">
                <div class="content">
                  <h3 class="title is-5">SafeCarGoal2(back)</h3>
                  <img src="./static/images/carg2.gif"
                            class="interpolation-image"
                            alt="tasks"/>
                </div>
              </div>
            </div>

            <!-- Re-rendering. -->
            <div class="column">
              <div class="content">
                <h3 class="title is-4">Simulation experiment results</h3>
                <div class="content has-text-justified">
                  <p>
                    Offline experimental results. Comparing FOSP to baselines across five image-based safety tasks. The results for all three algorithms are obtained after training for 1 million steps
                  </p>
                </div>
            <div class="content has-text-centered">
              <!-- <video id="replay-video"
                    controls
                    muted
                    preload
                    playsinline
                    width="75%">
                <source src="./static/videos/replay.mp4"
                        type="video/mp4">
              </video> -->
              <img src="./static/images/offline.png"
                    class="interpolation-image"
                    alt="offline"/>
            </div>
              <!-- <div class="columns is-centered">
                <div class="column content">
                  <p>
                    Online experimental results. Comparing FOSP to baselines across five image-based safety tasks in online fine-tuning. The results for all three model-based algorithms are obtained after fine-tuning for 750,000 steps.
                    The dashed lines represent the benchmark results for CPO and PPO-Lagrangian after 10 million training steps across all tasks.
                  </p>
                  <img src="./static/images/online2.png"
                    class="interpolation-image"
                    alt="online"/>
                  </video>
                </div>
              </div> -->
            <div class="content has-text-justified">
              <p>
                Online experimental results. Comparing FOSP to baselines across five image-based safety tasks in online fine-tuning. The results for all three model-based algorithms are obtained after fine-tuning for 750,000 steps.
                    The dashed lines represent the benchmark results for CPO and PPO-Lagrangian after 10 million training steps across all tasks.
              </p>
            </div>
            <div class="content has-text-centered">
              <img src="./static/images/online2.png"
                    class="interpolation-image"
                    alt="online"/>
            </div>
            <!--/ Re-rendering. -->

          </div>
        </div>
      </div>
    </section>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{cao2024fospfinetuningofflinesafe,
      title={FOSP: Fine-tuning Offline Safe Policy through World Models}, 
      author={Chenyang Cao and Yucheng Xin and Silang Wu and Longxiang He and Zichen Yan and Junbo Tan and Xueqian Wang},
      year={2024},
      eprint={2407.04942}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Sunlighted" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Page template borrowed from <a rel="license"
            href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
</body>
</html>
